{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-principal",
   "metadata": {},
   "source": [
    "# Quantum Process Tomography via Neural Networks\n",
    "## SU(2) Transformations\n",
    "___\n",
    "\n",
    "This notebook performs the process tomography for the numerical experiments proposed in our paper 'Retrieving unitary polarization transformations via optimized quantum tomography'.\n",
    " \n",
    "\n",
    "   The notebook is organized as follows: \n",
    "\n",
    "   1. Importing the synthetic data\n",
    "   2. Importing the network and performing the process tomography with 6 measurements\n",
    "   3. Evaluating the fidelity of the reconstruction for each process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-grocery",
   "metadata": {},
   "source": [
    "First, the required libraries are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GaussianDropout\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-appreciation",
   "metadata": {},
   "source": [
    "By running the following cell, you import the experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = \"0\"\n",
    "path = \"dataset/\"+ error\n",
    "\n",
    "LL = np.loadtxt(path + \"/LL.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "HH = np.loadtxt(path + \"/HH.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "HL = np.loadtxt(path + \"/HL.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "LD = np.loadtxt(path + \"/LD.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "LH = np.loadtxt(path + \"/LH.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "HD = np.loadtxt(path + \"/HD.txt\", dtype=\"f\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-classics",
   "metadata": {},
   "source": [
    "If available, you can import the theoretical $U_{Th}$ to compute the fidelity of the reconstructed process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset\"\n",
    "theta_th = np.loadtxt(path + \"/random_Theta.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "nx_th = np.loadtxt(path + \"/random_nx.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "ny_th = np.loadtxt(path + \"/random_ny.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "nz_th = np.loadtxt(path + \"/random_nz.txt\", dtype=\"f\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-audit",
   "metadata": {},
   "source": [
    "The function `compute_unitary` is used to compute the unitary $U$, given the parameters $\\Theta\\in[0,\\pi]$ and $\\mathbf{n}=(n_x,n_y,n_z)$ according to:\n",
    "\n",
    "\\begin{equation}\n",
    "U=\\begin{pmatrix}\n",
    "\\cos \\Theta -i \\sin \\Theta \\,n_z && -i\\sin \\Theta \\,(n_x-i n_y)\\\\\n",
    "-i\\sin \\Theta \\,(n_x+i n_y) && \\cos \\Theta + i \\sin \\Theta \\,n_z\n",
    "\\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unitary(Theta, nx, ny, nz):\n",
    "    I = np.array([[1, 0], [0, 1]])\n",
    "    sx = np.matrix([[0, 1], [1, 0]])\n",
    "    sy = np.matrix([[0, -1j], [1j, 0]])\n",
    "    sz = np.matrix([[1, 0], [0, -1]])\n",
    "    return np.cos(Theta) * I - 1j * np.sin(Theta) * (nx * sx + ny * sy + nz * sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-quest",
   "metadata": {},
   "source": [
    "The function `fidelity` is used to compute the function used to measure the \"distance\" between the reconstructed and theoretical unitaries:\n",
    "\n",
    "\\begin{equation}\n",
    "F=\\frac{1}{2}\\,\\biggl|Tr(U_\\text{th}^{\\dagger}U_\\text{exp})\\biggr|\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(mat1,mat2):\n",
    "    prod=np.trace(np.dot(np.conjugate(mat1.T),mat2))\n",
    "    \n",
    "    return 0.5*np.abs(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-discretion",
   "metadata": {},
   "source": [
    "Finally, we set the total number of evolutions to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of evolutions\n",
    "num_unit=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-sociology",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### Neural Network Reconstruction with 6 measurements\n",
    "\n",
    "The following cell imports the network trained to reconstruct the evolutions with 6 inputs. \n",
    "The set of measurements is  $[LL, LH, LD, HL, HH, HD]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(r'./models/NN_6in.json', 'r') #path of NN 6 inputs json file\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model6 = tf.keras.models.model_from_json(loaded_model_json)\n",
    "loaded_model6.load_weights(r'./models/NN_6in.h5') #path of NN 6 inputs h5 file\n",
    "\n",
    "data6=np.zeros([num_unit,6])\n",
    "data6[:,0]=LL\n",
    "data6[:,1]=LH\n",
    "data6[:,2]=LD\n",
    "data6[:,3]=HL\n",
    "data6[:,4]=HH\n",
    "data6[:,5]=HD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-copyright",
   "metadata": {},
   "source": [
    "We proceed with the network prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6=loaded_model6.predict(data6)\n",
    "theta_vect6=y_pred6[:,0]*np.pi\n",
    "nx_vect6=y_pred6[:,1]*2 -1 \n",
    "ny_vect6=(y_pred6[:,2]*2 -1)*np.sqrt(1-nx_vect6**2)\n",
    "\n",
    "nz_vect6=np.sqrt(abs(1-nx_vect6**2-ny_vect6**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-project",
   "metadata": {},
   "source": [
    "The fidelities of individual reconstructions are calculated and plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fvals6=np.zeros(num_unit)\n",
    "\n",
    "for i in range(num_unit):\n",
    "    netU=compute_unitary(theta_vect6[i],nx_vect6[i],ny_vect6[i],nz_vect6[i])\n",
    "    thU=compute_unitary(theta_th[i],nx_th[i],ny_th[i],nz_th[i])\n",
    "    Fvals6[i]=fidelity(netU,thU)\n",
    "\n",
    "plt.plot(range(num_unit), Fvals6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-wireless",
   "metadata": {},
   "source": [
    "Average fidelity and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Fvals6), np.sqrt(np.var(Fvals6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b1749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
