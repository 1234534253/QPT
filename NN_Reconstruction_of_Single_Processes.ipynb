{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-principal",
   "metadata": {},
   "source": [
    "# Quantum Process Tomography via Neural Networks\n",
    "## Single SU(2) Transformations\n",
    "___\n",
    "\n",
    "This notebook performs the process tomography for the numerical experiments proposed in our paper 'Retrieving complex polarization transformations via optimized quantum process tomography'.\n",
    " \n",
    "\n",
    "   The notebook is organized as follows: \n",
    "\n",
    "   1. Importing the synthetic data\n",
    "   2. Importing the correct network and performing the genetic recostruction with 6 measurements\n".
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-grocery",
   "metadata": {},
   "source": [
    "First, the required libraries are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GaussianDropout\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-appreciation",
   "metadata": {},
   "source": [
    "By running the following cell, you import the experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset_gaussian/\"\n",
    "LL = np.loadtxt(path + \"/LL.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "DL = np.loadtxt(path + \"/DL.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "HH = np.loadtxt(path + \"/HH.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "HL = np.loadtxt(path + \"/HL.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "LD = np.loadtxt(path + \"/LD.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "LH = np.loadtxt(path + \"/LH.txt\", dtype=\"f\", delimiter=\"\\t\")\n",
    "HD = np.loadtxt(path + \"/HD.txt\", dtype=\"f\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-classics",
   "metadata": {},
   "source": [
    "If available, you can import the theoretical $U_{Th}$ to compute the fidelity of the reconstructed process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select correct path\n",
    "theta_th=np.loadtxt(\"dataset_gaussian//random_Theta.txt\", dtype='f', delimiter='\\t')\n",
    "nx_th=np.loadtxt(\"dataset_gaussian//random_nx.txt\", dtype='f', delimiter='\\t')\n",
    "ny_th=np.loadtxt(\"dataset_gaussian//random_ny.txt\", dtype='f', delimiter='\\t')\n",
    "nz_th=np.loadtxt(\"dataset_gaussian//random_nz.txt\", dtype='f', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-audit",
   "metadata": {},
   "source": [
    "The function `compute_unitary` is used to compute the unitary $U$, given the parameters $\\Theta\\in[0,\\pi]$ and $\\mathbf{n}=(n_x,n_y,n_z)$ according to:\n",
    "\n",
    "\\begin{equation}\n",
    "U=\\begin{pmatrix}\n",
    "\\cos \\Theta -i \\sin \\Theta \\,n_z && -i\\sin \\Theta \\,(n_x-i n_y)\\\\\n",
    "-i\\sin \\Theta \\,(n_x+i n_y) && \\cos \\Theta + i \\sin \\Theta \\,n_z\n",
    "\\end{pmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unitary(Theta, nx, ny, nz):\n",
    "    I = np.array([[1, 0], [0, 1]])\n",
    "    sx = np.matrix([[0, 1], [1, 0]])\n",
    "    sy = np.matrix([[0, -1j], [1j, 0]])\n",
    "    sz = np.matrix([[1, 0], [0, -1]])\n",
    "    return np.cos(Theta) * I - 1j * np.sin(Theta) * (nx * sx + ny * sy + nz * sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-quest",
   "metadata": {},
   "source": [
    "The function `fidelity` is used to compute the function used to measure the \"distance\" between the reconstructed and theoretical unitaries:\n",
    "\n",
    "\\begin{equation}\n",
    "F=\\frac{1}{2}\\,\\biggl|Tr(U_\\text{th}^{\\dagger}U_\\text{exp})\\biggr|\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(mat1,mat2):\n",
    "    prod=np.trace(np.dot(np.conjugate(mat1.T),mat2))\n",
    "    \n",
    "    return 0.5*np.abs(prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-discretion",
   "metadata": {},
   "source": [
    "Finally, we set the total number of evolutions to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of evolutions\n",
    "num_unit=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-sociology",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### Neural Network Reconstruction with 6 measurements\n",
    "\n",
    "The following cell imports the network trained to reconstruct the evolutions with 6 inputs. \n",
    "The set of measurements is  $[LL, LH, LD, HL, HH, HD]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(r'./models/NN_6in.json', 'r') #path of NN 6 inputs json file\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model6 = tf.keras.models.model_from_json(loaded_model_json)\n",
    "loaded_model6.load_weights(r'./models/NN_6in.h5') #path of NN 6 inputs h5 file\n",
    "\n",
    "data6=np.zeros([num_unit,6])\n",
    "data6[:,0]=LL\n",
    "data6[:,1]=LH\n",
    "data6[:,2]=LD\n",
    "data6[:,3]=HL\n",
    "data6[:,4]=HH\n",
    "data6[:,5]=HD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-copyright",
   "metadata": {},
   "source": [
    "We proceed with the network prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6=loaded_model6.predict(data6)\n",
    "theta_vect6=y_pred6[:,0]*np.pi\n",
    "nx_vect6=y_pred6[:,1]*2 -1 \n",
    "ny_vect6=(y_pred6[:,2]*2 -1)*np.sqrt(1-nx_vect6**2)\n",
    "\n",
    "nz_vect6=np.sqrt(abs(1-nx_vect6**2-ny_vect6**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-project",
   "metadata": {},
   "source": [
    "The fidelities of individual reconstructions are calculated and plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fvals6=np.zeros(num_unit)\n",
    "\n",
    "for i in range(num_unit):\n",
    "    netU=compute_unitary(theta_vect6[i],nx_vect6[i],ny_vect6[i],nz_vect6[i])\n",
    "    thU=compute_unitary(theta_th[i],nx_th[i],ny_th[i],nz_th[i])\n",
    "    Fvals6[i]=fidelity(netU,thU)\n",
    "\n",
    "plt.plot(range(num_unit), Fvals6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-wireless",
   "metadata": {},
   "source": [
    "Average fidelity and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Fvals6), np.sqrt(np.var(Fvals6))"
   ]
  },
{
   "cell_type": "markdown",
   "id": "d92a708f",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### Neural Network Reconstruction with 5 measurements\n",
    "\n",
    "The following cell imports the network trained to reconstruct the evolutions with 5 inputs. \n",
    "The set of measurements is  $[LL, LH, LD, HH, HD]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(r'./models/NN_5in.json', 'r') #path of NN 5 inputs json file\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model5 = tf.keras.models.model_from_json(loaded_model_json)\n",
    "loaded_model5.load_weights(r'./models/NN_5in.h5') #path of NN 5 inputs h5 file\n",
    "\n",
    "data5=np.zeros([num_unit,5])\n",
    "data5[:,0]=LL\n",
    "data5[:,1]=LH\n",
    "data5[:,2]=LD\n",
    "data5[:,3]=HH\n",
    "data5[:,4]=HD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d842b",
   "metadata": {},
   "source": [
    "We proceed with the network prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5=loaded_model5.predict(data5)\n",
    "theta_vect5=y_pred5[:,0]*np.pi\n",
    "nx_vect5=y_pred5[:,1]*2 -1 \n",
    "ny_vect5=(y_pred5[:,2]*2 -1)*np.sqrt(1-nx_vect5**2)\n",
    "\n",
    "nz_vect5=np.sqrt(abs(1-nx_vect5**2-ny_vect5**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8c2a9",
   "metadata": {},
   "source": [
    "The fidelities of individual reconstructions are calculated and plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d031b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Fvals5=np.zeros(num_unit)\n",
    "\n",
    "for i in range(num_unit):\n",
    "    netU=compute_unitary(theta_vect5[i],nx_vect5[i],ny_vect5[i],nz_vect5[i])\n",
    "    thU=compute_unitary(theta_th[i],nx_th[i],ny_th[i],nz_th[i])\n",
    "    Fvals5[i]=fidelity(netU,thU)\n",
    "\n",
    "plt.plot(range(num_unit), Fvals5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efdddd",
   "metadata": {},
   "source": [
    "Average fidelity and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Fvals5), np.sqrt(np.var(Fvals5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-concentration",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### Neural Network Reconstruction with 4 measurements\n",
    "\n",
    "The following cell imports the network trained to reconstruct the evolutions with 4 inputs. \n",
    "The set of measurements is  $[LL, LH, HH, HD]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(r'./models/NN_4in.json', 'r') #path of NN 4 inputs json file\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model4 = tf.keras.models.model_from_json(loaded_model_json)\n",
    "loaded_model4.load_weights(r'./models/NN_4in.h5') #path of NN 4 inputs h5 file\n",
    "\n",
    "data4=np.zeros([num_unit,4])\n",
    "data4[:,0]=LL\n",
    "data4[:,1]=LH\n",
    "data4[:,2]=HH\n",
    "data4[:,3]=HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4=loaded_model4.predict(data4)\n",
    "theta_vect4=y_pred4[:,0]*np.pi\n",
    "nx_vect4=y_pred4[:,1]*2 -1 \n",
    "ny_vect4=(y_pred4[:,2]*2 -1)*np.sqrt(1-nx_vect4**2)\n",
    "\n",
    "nz_vect4=np.sqrt(abs(1-nx_vect4**2-ny_vect4**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf07d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fvals4=np.zeros(num_unit)\n",
    "\n",
    "for i in range(num_unit):\n",
    "    netU=compute_unitary(theta_vect4[i],nx_vect4[i],ny_vect4[i],nz_vect4[i])\n",
    "    thU=compute_unitary(theta_th[i],nx_th[i],ny_th[i],nz_th[i])\n",
    "    Fvals4[i]=fidelity(netU,thU)\n",
    "\n",
    "plt.plot(range(num_unit), Fvals4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eae750",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Fvals4), np.sqrt(np.var(Fvals4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824cccde",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "### Neural Network Reconstruction with 3 measurements\n",
    "\n",
    "The following cell imports the network trained to reconstruct the evolutions with 3 inputs. \n",
    "The set of measurements is  $[LL, LH, HD]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(r'./models/NN_3in.json', 'r') #path of NN 3 inputs json file\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model3 = tf.keras.models.model_from_json(loaded_model_json)\n",
    "loaded_model3.load_weights(r'./models/NN_3in.h5') #path of NN 3 inputs h5 file\n",
    "\n",
    "data3=np.zeros([num_unit,3])\n",
    "data3[:,0]=LL\n",
    "data3[:,1]=LH\n",
    "data3[:,2]=HD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3=loaded_model3.predict(data3)\n",
    "theta_vect3=y_pred3[:,0]*np.pi\n",
    "nx_vect3=y_pred3[:,1]*2 -1 \n",
    "ny_vect3=(y_pred3[:,2]*2 -1)*np.sqrt(1-nx_vect3**2)\n",
    "\n",
    "nz_vect3=np.sqrt(abs(1-nx_vect3**2-ny_vect3**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3490aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fvals3=np.zeros(num_unit)\n",
    "\n",
    "for i in range(num_unit):\n",
    "    netU=compute_unitary(theta_vect3[i],nx_vect3[i],ny_vect3[i],nz_vect3[i])\n",
    "    thU=compute_unitary(theta_th[i],nx_th[i],ny_th[i],nz_th[i])\n",
    "    Fvals3[i]=fidelity(netU,thU)\n",
    "\n",
    "plt.plot(range(num_unit), Fvals3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Fvals3), np.sqrt(np.var(Fvals3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
